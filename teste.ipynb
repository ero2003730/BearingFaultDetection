{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Devices:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU details:  {'device_name': 'METAL'}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "devices = tf.config.list_physical_devices()\n",
    "print(\"\\nDevices: \", devices)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  details = tf.config.experimental.get_device_details(gpus[0])\n",
    "  print(\"GPU details: \", details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo na GPU: 0.0438 segundos\n",
      "Tempo na CPU: 0.5467 segundos\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# Configurar tamanhos das matrizes\n",
    "matrix_size = 3000\n",
    "\n",
    "# Função para medir o tempo\n",
    "def benchmark(device_name):\n",
    "    with tf.device(device_name):  # Define o dispositivo (CPU ou GPU)\n",
    "        a = tf.random.uniform((matrix_size, matrix_size))\n",
    "        b = tf.random.uniform((matrix_size, matrix_size))\n",
    "        start_time = time.time()\n",
    "        for _ in range(10):  # Realizar 10 operações para melhor medição\n",
    "            c = tf.matmul(a, b)\n",
    "        tf.experimental.numpy.asarray(c)  # Garante que a operação é concluída\n",
    "        elapsed_time = time.time() - start_time\n",
    "    return elapsed_time\n",
    "\n",
    "# Testar na GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    gpu_time = benchmark('/GPU:0')\n",
    "    print(f\"Tempo na GPU: {gpu_time:.4f} segundos\")\n",
    "else:\n",
    "    print(\"Nenhuma GPU detectada.\")\n",
    "\n",
    "# Testar na CPU\n",
    "cpu_time = benchmark('/CPU:0')\n",
    "print(f\"Tempo na CPU: {cpu_time:.4f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo na GPU (MPS): 0.0023 segundos\n",
      "Tempo na CPU: 0.2212 segundos\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Configurar tamanho das matrizes\n",
    "matrix_size = 3000\n",
    "\n",
    "# Função para medir o tempo\n",
    "def benchmark(device):\n",
    "    a = torch.randn(matrix_size, matrix_size, device=device)\n",
    "    b = torch.randn(matrix_size, matrix_size, device=device)\n",
    "    torch.cuda.synchronize() if device.type == \"cuda\" else None  # Sincronizar antes de começar a medir\n",
    "    start_time = time.time()\n",
    "    for _ in range(10):  # Realizar 10 multiplicações de matrizes\n",
    "        c = torch.matmul(a, b)\n",
    "    torch.cuda.synchronize() if device.type == \"cuda\" else None  # Sincronizar para garantir a conclusão\n",
    "    elapsed_time = time.time() - start_time\n",
    "    return elapsed_time\n",
    "\n",
    "# Testar na GPU (MPS ou CUDA)\n",
    "if torch.backends.mps.is_available():\n",
    "    gpu_device = torch.device(\"mps\")\n",
    "    gpu_time = benchmark(gpu_device)\n",
    "    print(f\"Tempo na GPU (MPS): {gpu_time:.4f} segundos\")\n",
    "elif torch.cuda.is_available():\n",
    "    gpu_device = torch.device(\"cuda\")\n",
    "    gpu_time = benchmark(gpu_device)\n",
    "    print(f\"Tempo na GPU (CUDA): {gpu_time:.4f} segundos\")\n",
    "else:\n",
    "    print(\"Nenhuma GPU disponível.\")\n",
    "\n",
    "# Testar na CPU\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "cpu_time = benchmark(cpu_device)\n",
    "print(f\"Tempo na CPU: {cpu_time:.4f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo na GPU: 0.0438 segundos\n",
      "Tempo na CPU: 0.5467 segundos\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# Configurar tamanhos das matrizes\n",
    "matrix_size = 3000\n",
    "\n",
    "# Função para medir o tempo\n",
    "def benchmark(device_name):\n",
    "    with tf.device(device_name):  # Define o dispositivo (CPU ou GPU)\n",
    "        a = tf.random.uniform((matrix_size, matrix_size))\n",
    "        b = tf.random.uniform((matrix_size, matrix_size))\n",
    "        start_time = time.time()\n",
    "        for _ in range(10):  # Realizar 10 operações para melhor medição\n",
    "            c = tf.matmul(a, b)\n",
    "        tf.experimental.numpy.asarray(c)  # Garante que a operação é concluída\n",
    "        elapsed_time = time.time() - start_time\n",
    "    return elapsed_time\n",
    "\n",
    "# Testar na GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    gpu_time = benchmark('/GPU:0')\n",
    "    print(f\"Tempo na GPU: {gpu_time:.4f} segundos\")\n",
    "else:\n",
    "    print(\"Nenhuma GPU detectada.\")\n",
    "\n",
    "# Testar na CPU\n",
    "cpu_time = benchmark('/CPU:0')\n",
    "print(f\"Tempo na CPU: {cpu_time:.4f} segundos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
